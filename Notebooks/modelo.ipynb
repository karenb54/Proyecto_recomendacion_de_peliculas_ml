{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo las librerias correspondientes para la creacion del modelo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtencion y organizacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del DataFrame: (24004, 12)\n"
     ]
    }
   ],
   "source": [
    "# Cargo el dataset modificado en el EDA\n",
    "\n",
    "dataframe_unido_modelo = pd.read_parquet('../Datasets/dataset_unido_modelo')\n",
    "print(f\"Dimensiones del DataFrame: {dataframe_unido_modelo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combino las columnas relevantes en una sola columna para la vectorización\n",
    "\n",
    "dataframe_unido_modelo['texto_combinado'] = (\n",
    "    dataframe_unido_modelo['cast_name_actor'] + ' ' +\n",
    "    dataframe_unido_modelo['crew_name_member'] + ' ' +\n",
    "    dataframe_unido_modelo['overview']\n",
    ")\n",
    "# Reemplazo valores nulos en la columna combinada con una cadena vacía\n",
    "dataframe_unido_modelo['texto_combinado'] = dataframe_unido_modelo['texto_combinado'].fillna('')\n",
    "\n",
    "# Elimino caracteres no deseados como comas\n",
    "dataframe_unido_modelo['texto_combinado'] = dataframe_unido_modelo['texto_combinado'].str.replace(',', ' ')\n",
    "\n",
    "# guardo el archivo que va a ser usado en la api\n",
    "dataframe_unido_modelo.to_parquet('../Datasets/dataset_unido_modelo', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vectorizacion de las características numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizo las características numéricas\n",
    "\n",
    "caracteristicas_numericas = ['budget', 'revenue', 'vote_count', 'popularity']\n",
    "escala = StandardScaler()\n",
    "caracteristicas_numericas_normalizadas = escala.fit_transform(dataframe_unido_modelo[caracteristicas_numericas])\n",
    "matrix_numerica_escalada = csr_matrix(caracteristicas_numericas_normalizadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Vectorización de las características categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizo el género y aplico un peso mayor a esta matriz\n",
    "\n",
    "vectorizar_genero = TfidfVectorizer(stop_words='english')\n",
    "matrix_tfidf_genero = vectorizar_genero.fit_transform(dataframe_unido_modelo['name_genre'])\n",
    "peso_del_genero = 6.0\n",
    "matrix_tfidf_genero_ponderado = peso_del_genero * matrix_tfidf_genero\n",
    "\n",
    "# Vectorizo el texto combinado (actores, directores, overview)\n",
    "\n",
    "vectorizar_texto_combinado = TfidfVectorizer(stop_words='english')\n",
    "matrix_tfidf_combinado = vectorizar_texto_combinado.fit_transform(dataframe_unido_modelo['texto_combinado'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combinación de características:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combino la matriz numérica, la matriz ponderada de géneros y la matriz de texto combinado\n",
    "caracteristicas_combinadas = hstack([matrix_numerica_escalada, matrix_tfidf_genero_ponderado, matrix_tfidf_combinado])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Realizar el calculo de la similitud del coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseguro que la matriz combinada es de tipo csr_matrix\n",
    "if not isinstance(caracteristicas_combinadas, csr_matrix):\n",
    "    caracteristicas_combinadas = csr_matrix(caracteristicas_combinadas)\n",
    "\n",
    "# Reduzco la dimensionalidad con SVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "caracteristicas_reducidas = svd.fit_transform(caracteristicas_combinadas)\n",
    "\n",
    "# Calculo la matriz de similitud del coseno\n",
    "similitud_del_coseno = cosine_similarity(caracteristicas_reducidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener las mejores recomendaciones\n",
    "# Preproceso los titulos en minusculas solo una vez fuera de la funcion\n",
    "dataframe_unido_modelo['title_lower'] = dataframe_unido_modelo['title'].str.lower()\n",
    "def recomendacion(title: str):\n",
    "    \"\"\"\n",
    "    Recomienda películas similares a una película dada basada en la similitud del coseno.\n",
    "\n",
    "    Parámetros:\n",
    "        title: El título de la película para la cual se desean obtener recomendaciones.\n",
    "    \n",
    "    Retorna:\n",
    "        Si el título es válido, retorna una lista de 5 títulos de películas recomendadas que son más similares.\n",
    "        Si el título no es válido, retorna un mensaje indicando que el título no está disponible.\n",
    "    \"\"\"\n",
    "    # Normalizo el título para comparar sin importar mayúsculas/minúsculas\n",
    "    title = title.lower()\n",
    "\n",
    "    # Verifico si el título está en el DataFrame\n",
    "    if title not in dataframe_unido_modelo['title_lower'].values:\n",
    "        return {\"error\": f\"La película '{title}' no se encuentra dentro de la muestra de datos.\"}\n",
    "\n",
    "    # Obtengo el índice de la película dada\n",
    "    idx = dataframe_unido_modelo[dataframe_unido_modelo['title_lower'] == title].index[0]\n",
    "\n",
    "    # Si la matriz de similitud es dispersa, trabajo directamente con ella sin convertir a densa\n",
    "    if isinstance(similitud_del_coseno, csr_matrix):\n",
    "        sim_scores = similitud_del_coseno[idx].toarray().flatten()\n",
    "    else:\n",
    "        sim_scores = similitud_del_coseno[idx]\n",
    "\n",
    "    # Obtener las 5 tuplas más cercanas usando min-heap\n",
    "    top_5_indices = np.argsort(sim_scores)[::-1]  # Ordena de mayor a menor\n",
    "    top_5_indices = top_5_indices[sim_scores[top_5_indices] > 0]  # Filtra las similitudes positivas\n",
    "    top_5_indices = [i for i in top_5_indices if i != idx][:5]  # Excluye la película misma y toma las 5 mejores\n",
    "\n",
    "    # Obtener los títulos de las películas recomendadas\n",
    "    top_5_titles = dataframe_unido_modelo.iloc[top_5_indices]['title'].tolist()\n",
    "\n",
    "    return {\"recomendaciones\": top_5_titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendaciones para 'The Avengers':\n",
      "{'recomendaciones': ['Out of Time', 'The Missing', 'Hard Rain', 'U.S. Marshals', 'Broken City']}\n",
      "\n",
      "Recomendaciones para 'Men in Black':\n",
      "{'recomendaciones': ['The Incredibles', 'Terminator 2: Judgment Day', 'Sherlock Holmes', 'The Bourne Ultimatum', 'Captain America: The Winter Soldier']}\n",
      "\n",
      "Recomendaciones para 'toy story':\n",
      "{'recomendaciones': ['Despicable Me', 'Ice Age', 'Monsters, Inc.', 'Aladdin', 'Toy Story 2']}\n",
      "\n",
      "Recomendaciones para 'john wick:\n",
      "{'recomendaciones': ['Baby Driver', 'Wonder Woman', 'Minions', 'Deadpool', 'Gone Girl']}\n",
      "\n",
      "Recomendaciones para 'saw':\n",
      "{'recomendaciones': ['The Purge: Anarchy', '28 Days Later', 'Insidious', 'It Follows', 'Shaun of the Dead']}\n",
      "{'error': \"La película 'bee' no se encuentra dentro de la muestra de datos.\"}\n"
     ]
    }
   ],
   "source": [
    "# Realizo una verificacion con distintos titulos de peliculas para observar el funcionamiento del modelo\n",
    "\n",
    "print(\"Recomendaciones para 'The Avengers':\")\n",
    "print(recomendacion('The Avengers'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'Men in Black':\")\n",
    "print(recomendacion('Men in Black'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'toy story':\")\n",
    "print(recomendacion('toy story'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'john wick:\")\n",
    "print(recomendacion('john wick'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'saw':\")\n",
    "print(recomendacion('saw'))\n",
    "\n",
    "print(recomendacion('bee'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para reducir la memoria en la api se tomo una version mas reducida del modelo anterior pero ambos funcionan con la misma cantidad de datos solo que en la api se crearon dos funciones y la similitud del coseno se creo dentro de la funcion de recomendaciones, se dejan las dos versiones con sus respectivas pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizo las características numéricas y género en funciones separadas para reducir el uso de memoria.\n",
    "def procesar_datos(dataframe):\n",
    "    \"\"\"\n",
    "    Procesa los datos del DataFrame para generar una matriz de características combinadas y reducidas.\n",
    "\n",
    "    Este procesamiento incluye:\n",
    "    1. Escalado de las características numéricas.\n",
    "    2. Vectorización y ponderación del genero.\n",
    "    3. Vectorización del texto combinado (actores, directores, overview).\n",
    "    4. Combinación de todas las matrices vectorizadas en una sola.\n",
    "    5. Reducción de dimensionalidad mediante SVD para obtener una representación mas compacta.\n",
    "\n",
    "    Parametros:\n",
    "    \n",
    "        dataframe : el dataFrame 'dataframe_unido_modelo' que contiene las caracteristicas numericas, los generos y el texto combinado.\n",
    "\n",
    "    Retorna:\n",
    "    \n",
    "        caracteristicas_reducidas : una matriz con las caracteristicas combinadas y reducidas dimensionalmente.\n",
    "    \"\"\"\n",
    "    # Escalo las caracteristicas numericas\n",
    "    caracteristicas_numericas = ['budget', 'revenue', 'vote_count', 'popularity']\n",
    "    escala = StandardScaler()\n",
    "    caracteristicas_numericas_normalizadas = escala.fit_transform(dataframe[caracteristicas_numericas])\n",
    "    matrix_numerica_escalada = csr_matrix(caracteristicas_numericas_normalizadas)\n",
    "    \n",
    "    # Vectorizo y pondero el genero\n",
    "    vectorizar_genero = TfidfVectorizer(stop_words='english')\n",
    "    matrix_tfidf_genero = vectorizar_genero.fit_transform(dataframe['name_genre'])\n",
    "    peso_del_genero = 6.0\n",
    "    matrix_tfidf_genero_ponderado = peso_del_genero * matrix_tfidf_genero\n",
    "    \n",
    "    # Vectorizo el texto combinado (actores, directores, overview)\n",
    "    vectorizar_texto_combinado = TfidfVectorizer(stop_words='english')\n",
    "    matrix_tfidf_combinado = vectorizar_texto_combinado.fit_transform(dataframe['texto_combinado'])\n",
    "\n",
    "    # Combino todas las matrices en una sola (caracteristicas numericas, genero y texto combinado)\n",
    "    caracteristicas_combinadas = hstack([matrix_numerica_escalada, matrix_tfidf_genero_ponderado, matrix_tfidf_combinado])\n",
    "    \n",
    "    # Reduzco la dimensionalidad con SVD a 50 componentes para mantenerlo liviano\n",
    "    svd = TruncatedSVD(n_components=50)\n",
    "    caracteristicas_reducidas = svd.fit_transform(caracteristicas_combinadas)\n",
    "    \n",
    "    return caracteristicas_reducidas\n",
    "\n",
    "# Proceso el DataFrame (solo se hace una vez)\n",
    "dataframe_unido_modelo['title_lower'] = dataframe_unido_modelo['title'].str.lower()\n",
    "caracteristicas_reducidas = procesar_datos(dataframe_unido_modelo)\n",
    "\n",
    "# Creo una funcion de recomendacion con el cálculo de similitud del coseno dentro\n",
    "def recomendaciones(title: str):\n",
    "    \"\"\"\n",
    "    Recomienda películas similares a una película dada basada en la similitud del coseno.\n",
    "    \n",
    "    Parámetros:\n",
    "        title: El título de la película para la cual se desean obtener recomendaciones.\n",
    "        \n",
    "    Retorna:\n",
    "        Una lista de 5 títulos de películas recomendadas, o un mensaje de error si no se encuentra el título.\n",
    "    \"\"\"\n",
    "    # Normalizo el título para comparar sin importar mayúsculas/minúsculas\n",
    "    title = title.lower()\n",
    "\n",
    "    # Verifico si el título está en el DataFrame\n",
    "    if title not in dataframe_unido_modelo['title_lower'].values:\n",
    "        return {\"error\": f\"La película '{title}' no se encuentra en la base de datos.\"}\n",
    "\n",
    "    # Obtengo el índice de la película dada\n",
    "    idx = dataframe_unido_modelo[dataframe_unido_modelo['title_lower'] == title].index[0]\n",
    "\n",
    "    # Calculo la matriz de similitud del coseno sobre la marcha para evitar mantenerla en memoria\n",
    "    sim_scores = cosine_similarity(caracteristicas_reducidas[idx].reshape(1, -1), caracteristicas_reducidas).flatten()\n",
    "\n",
    "    # Obtener las 5 películas más similares, excluyendo la misma película\n",
    "    top_5_indices = np.argsort(sim_scores)[::-1][1:6]  # [1:6] excluye la película misma\n",
    "    top_5_titles = dataframe_unido_modelo.iloc[top_5_indices]['title'].tolist()\n",
    "\n",
    "    return {\"recomendaciones\": top_5_titles}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendaciones para 'The Avengers':\n",
      "{'recomendaciones': ['Out of Time', 'The Missing', 'Hard Rain', 'U.S. Marshals', 'Broken City']}\n",
      "\n",
      "Recomendaciones para 'Men in Black':\n",
      "{'recomendaciones': ['The Incredibles', 'Terminator 2: Judgment Day', 'Sherlock Holmes', 'The Bourne Ultimatum', 'Captain America: The Winter Soldier']}\n",
      "\n",
      "Recomendaciones para 'toy story':\n",
      "{'recomendaciones': ['Despicable Me', 'Ice Age', 'Monsters, Inc.', 'Aladdin', 'Toy Story 2']}\n",
      "\n",
      "Recomendaciones para 'john wick:\n",
      "{'recomendaciones': ['Baby Driver', 'Wonder Woman', 'Minions', 'Deadpool', 'Gone Girl']}\n",
      "\n",
      "Recomendaciones para 'saw':\n",
      "{'recomendaciones': ['The Purge: Anarchy', '28 Days Later', 'Insidious', 'It Follows', 'Shaun of the Dead']}\n",
      "{'error': \"La película 'bee' no se encuentra en la base de datos.\"}\n"
     ]
    }
   ],
   "source": [
    "# Realizo una verificacion con distintos titulos de peliculas para observar el funcionamiento del modelo\n",
    "\n",
    "print(\"Recomendaciones para 'The Avengers':\")\n",
    "print(recomendaciones('The Avengers'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'Men in Black':\")\n",
    "print(recomendaciones('Men in Black'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'toy story':\")\n",
    "print(recomendaciones('toy story'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'john wick:\")\n",
    "print(recomendaciones('john wick'))\n",
    "\n",
    "print(\"\\nRecomendaciones para 'saw':\")\n",
    "print(recomendaciones('saw'))\n",
    "\n",
    "print(recomendaciones('bee'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
